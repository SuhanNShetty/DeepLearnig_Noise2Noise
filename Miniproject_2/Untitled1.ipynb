{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "orange-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "path_train = '../data/train_data.pkl'\n",
    "path_val = '../data/val_data.pkl'\n",
    "\n",
    "noisy_imgs_1, noisy_imgs_2 = torch.load(path_train)\n",
    "noisy_imgs_1 = noisy_imgs_1[0:1].cpu().float()/256\n",
    "noisy_imgs_2 = noisy_imgs_2[0:1].cpu().float()/256\n",
    "\n",
    "noisy_imgs , clean_imgs = torch.load(path_val)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "protecting-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conservative-landscape",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9525587e4ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input = torch.normal(mean=torch.zeros(20,10), std=torch.ones(20,10))\n",
    "target = input.sign()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "reliable-blowing",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-eee11c8150e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m ).to(device)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "# device = 'cpu'\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import torch \n",
    "import torchvision \n",
    "import torchvision.transforms as T \n",
    "from PIL import Image\n",
    "\n",
    "transform = T.ToPILImage()\n",
    "# model = UNet(m=10).to(device)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(32,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 32)\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size, nb_epochs = 50, 2\n",
    "\n",
    "input = noisy_imgs_1.to(device).type(torch.float)\n",
    "target = noisy_imgs_2.to(device).type(torch.float)\n",
    "\n",
    "valid_inp = noisy_imgs.to(device).float()/256\n",
    "valid_target = clean_imgs.to(device).float()/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "institutional-flood",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nb_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-687c1032d8ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_tot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nb_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "loss_tot = torch.zeros(nb_epochs)\n",
    "loss_valid = torch.zeros(nb_epochs)\n",
    "print(loss_tot)\n",
    "for e in tqdm(range(nb_epochs)):\n",
    "    model.train()\n",
    "    for i in range(len(input)):\n",
    "        with torch.autograd.graph.saved_tensors_hooks(pack_hook, unpack_hook):\n",
    "            output = model(input[i])\n",
    "            loss = mse(output, target[i])\n",
    "            loss_tot[e] += loss.item()    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    valid_output = model(valid_inp)\n",
    "    loss_valid[e] = mse(valid_output, valid_target).item()\n",
    "\n",
    "    if torch.remainder(torch.tensor(e), 100)==0:\n",
    "        plt.figure()\n",
    "        im = 0\n",
    "        im2 = 0\n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.imshow(transform(input[i][im]))\n",
    "        plt.colorbar()\n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.imshow(transform(output[im]))\n",
    "        plt.colorbar()\n",
    "        plt.subplot(2, 3, 3)\n",
    "        plt.imshow(transform(target[i][im]))\n",
    "        plt.colorbar()\n",
    "        plt.subplot(2, 3, 4)\n",
    "        plt.imshow(transform(valid_inp[im2]))\n",
    "        plt.colorbar()\n",
    "        plt.subplot(2, 3, 5)\n",
    "        plt.imshow(transform(valid_output[im2]))\n",
    "        plt.colorbar()\n",
    "        plt.subplot(2, 3, 6)\n",
    "        plt.imshow(transform(valid_target[im2]))\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "parallel-finance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MseLossBackward0 at 0x7f53a4eb7dc0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.grad_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sixth-crack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3, 32, 32])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "equal-glory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packing None\n",
      "Packing <MulBackward0 object at 0x7f53a41fe730>\n",
      "Unpacking None\n",
      "Unpacking <MulBackward0 object at 0x7f53a41fe9a0>\n",
      "tensor([[-2.6659e-04, -3.5663e-04, -3.2836e-04,  ..., -4.9033e-04,\n",
      "         -5.0753e-04, -5.0678e-04],\n",
      "        [-9.8017e-05, -1.1304e-04, -1.7355e-04,  ..., -1.6383e-04,\n",
      "         -1.4987e-04, -1.5968e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 1.2191e-04,  1.8352e-04,  1.2541e-04,  ...,  2.1039e-04,\n",
      "          2.8016e-04,  3.1215e-04],\n",
      "        [-1.2233e-04, -1.2401e-04, -1.0622e-04,  ..., -2.2852e-04,\n",
      "         -1.9523e-04, -2.0681e-04],\n",
      "        [-2.8068e-04, -2.1599e-04, -2.3331e-04,  ..., -3.2779e-04,\n",
      "         -1.9258e-04, -1.1005e-04]], device='cuda:0')\n",
      "tensor([-8.7733e-04, -6.6797e-05,  0.0000e+00, -5.3405e-05,  5.8503e-04,\n",
      "         1.6258e-04, -1.3052e-04, -2.8077e-04,  1.9067e-04, -3.8917e-04,\n",
      "        -1.3504e-03,  4.8111e-04,  4.4899e-04, -8.3343e-06, -6.0169e-04,\n",
      "         8.5928e-04, -1.0477e-04,  1.0479e-03, -2.1876e-04, -8.6635e-04,\n",
      "        -2.4738e-05,  0.0000e+00, -2.3143e-04,  7.5556e-05,  3.9079e-04,\n",
      "         1.3942e-04, -4.8908e-04, -2.2169e-04, -4.9554e-04, -1.7827e-05,\n",
      "         0.0000e+00, -1.2659e-03,  0.0000e+00, -8.4350e-04,  4.0472e-05,\n",
      "         2.3732e-04, -2.3110e-05,  3.7337e-04, -5.7116e-04,  0.0000e+00,\n",
      "        -3.0320e-04,  3.8579e-04,  0.0000e+00, -2.5285e-04,  1.3737e-04,\n",
      "        -3.1686e-04, -3.1202e-04,  2.1175e-04, -9.3343e-04, -4.2396e-04,\n",
      "         1.2142e-05, -2.8262e-04,  6.6992e-06, -3.4153e-04, -8.9704e-05,\n",
      "        -5.9730e-04,  1.7816e-04, -3.7559e-04,  0.0000e+00, -7.9032e-05,\n",
      "        -1.2821e-03, -8.1255e-04,  5.0036e-04,  1.6654e-03, -8.6557e-04,\n",
      "         8.1989e-04, -2.4877e-04, -1.2996e-04, -2.1290e-04,  5.3452e-04,\n",
      "         7.9760e-04,  1.3309e-04, -3.3973e-04, -1.9988e-04, -7.0924e-04,\n",
      "        -9.3013e-04, -5.4501e-04, -6.7772e-04, -2.4571e-04,  3.5342e-04,\n",
      "         7.7124e-04,  6.4289e-04,  9.0406e-05, -5.9731e-04,  1.9658e-05,\n",
      "         4.9682e-05, -1.7476e-04,  2.1463e-04,  3.8248e-04,  5.0809e-05,\n",
      "         5.5056e-04,  6.1229e-04,  0.0000e+00, -1.3805e-05, -2.4249e-04,\n",
      "         0.0000e+00,  1.1173e-04,  5.3134e-04, -4.2513e-04, -8.4910e-04],\n",
      "       device='cuda:0')\n",
      "tensor([[ 9.1832e-04,  6.0527e-04,  0.0000e+00,  ...,  1.9382e-03,\n",
      "          1.7403e-03,  1.3287e-03],\n",
      "        [-4.1892e-04, -3.1236e-04,  0.0000e+00,  ..., -9.7728e-04,\n",
      "         -7.6916e-04, -5.9253e-04],\n",
      "        [-2.1849e-04, -2.0103e-04,  0.0000e+00,  ..., -4.9055e-04,\n",
      "         -4.0517e-04, -3.1570e-04],\n",
      "        ...,\n",
      "        [-3.8439e-05, -7.9711e-05,  0.0000e+00,  ..., -2.6460e-04,\n",
      "         -3.5561e-04, -2.7659e-04],\n",
      "        [-2.5983e-05, -7.3980e-05,  0.0000e+00,  ..., -2.5183e-04,\n",
      "         -1.7773e-04, -1.3822e-04],\n",
      "        [-3.9637e-04, -1.8288e-04,  0.0000e+00,  ..., -6.4140e-04,\n",
      "         -5.1098e-04, -3.6567e-04]], device='cuda:0')\n",
      "tensor([ 0.0031, -0.0010, -0.0007,  0.0008,  0.0013, -0.0030, -0.0022, -0.0013,\n",
      "         0.0012,  0.0017,  0.0007, -0.0009, -0.0027, -0.0021, -0.0013, -0.0009,\n",
      "         0.0006, -0.0005, -0.0007, -0.0017,  0.0009,  0.0027,  0.0012,  0.0001,\n",
      "         0.0005,  0.0011, -0.0005,  0.0003, -0.0001, -0.0006, -0.0002, -0.0017],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def pack_hook(x):\n",
    "    print(\"Packing\", x.grad_fn)\n",
    "    return x\n",
    "\n",
    "def unpack_hook(x):\n",
    "    print(\"Unpacking\", x.grad_fn)\n",
    "    return x\n",
    "\n",
    "a = torch.ones(5, requires_grad=True) \n",
    "b = torch.ones(5, requires_grad=True) * 2\n",
    "with torch.autograd.graph.saved_tensors_hooks(pack_hook, unpack_hook):\n",
    "    y = a * b\n",
    "\n",
    "y.sum().backward()\n",
    "for param in model.parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "adolescent-radiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0430,  0.0758, -0.0567,  ...,  0.1674,  0.0716,  0.0896],\n",
      "        [ 0.1323, -0.0251,  0.1641,  ...,  0.0624,  0.0776, -0.0572],\n",
      "        [ 0.1056, -0.0842, -0.1403,  ..., -0.1336, -0.0180,  0.1026],\n",
      "        ...,\n",
      "        [ 0.0346,  0.1956,  0.0162,  ...,  0.1757,  0.0807, -0.0191],\n",
      "        [ 0.0521, -0.0734, -0.0705,  ...,  0.0295,  0.1058, -0.0603],\n",
      "        [ 0.0496, -0.0782, -0.0812,  ...,  0.0930, -0.1312,  0.0270]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[-2.6659e-04, -3.5663e-04, -3.2836e-04,  ..., -4.9033e-04,\n",
      "         -5.0753e-04, -5.0678e-04],\n",
      "        [-9.8017e-05, -1.1304e-04, -1.7355e-04,  ..., -1.6383e-04,\n",
      "         -1.4987e-04, -1.5968e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 1.2191e-04,  1.8352e-04,  1.2541e-04,  ...,  2.1039e-04,\n",
      "          2.8016e-04,  3.1215e-04],\n",
      "        [-1.2233e-04, -1.2401e-04, -1.0622e-04,  ..., -2.2852e-04,\n",
      "         -1.9523e-04, -2.0681e-04],\n",
      "        [-2.8068e-04, -2.1599e-04, -2.3331e-04,  ..., -3.2779e-04,\n",
      "         -1.9258e-04, -1.1005e-04]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([-0.0025, -0.0835, -0.0264, -0.0462,  0.0273,  0.0042, -0.0407,  0.0626,\n",
      "        -0.0760, -0.0721,  0.1727,  0.1658,  0.0547,  0.0187,  0.1117, -0.0449,\n",
      "         0.0959,  0.1103,  0.1552,  0.1188,  0.0353,  0.0102,  0.0981,  0.0673,\n",
      "        -0.0925,  0.1742,  0.0201,  0.1190, -0.0895,  0.0142, -0.0019,  0.0226,\n",
      "        -0.1004, -0.0596, -0.0452,  0.1428, -0.0648,  0.0185, -0.0660, -0.1582,\n",
      "         0.0185, -0.0606, -0.1398,  0.0726, -0.0945, -0.1459,  0.1191,  0.0852,\n",
      "         0.1157, -0.0768,  0.1111,  0.0161,  0.0622, -0.1040, -0.0680,  0.0861,\n",
      "        -0.0727, -0.0462, -0.1387, -0.1041,  0.0130, -0.0078,  0.0981,  0.0729,\n",
      "         0.1598,  0.1790,  0.1040,  0.0056,  0.1161,  0.0276, -0.0411, -0.0250,\n",
      "        -0.0674, -0.1325,  0.0966,  0.0274,  0.0089,  0.0162, -0.0462,  0.0728,\n",
      "        -0.0637, -0.0834, -0.0866,  0.1309,  0.1433, -0.1817,  0.1948,  0.1332,\n",
      "         0.0198,  0.0715, -0.0862,  0.0195, -0.1816, -0.0284,  0.0814, -0.0875,\n",
      "         0.1490,  0.0191,  0.0929, -0.0704], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([-8.7733e-04, -6.6797e-05,  0.0000e+00, -5.3405e-05,  5.8503e-04,\n",
      "         1.6258e-04, -1.3052e-04, -2.8077e-04,  1.9067e-04, -3.8917e-04,\n",
      "        -1.3504e-03,  4.8111e-04,  4.4899e-04, -8.3343e-06, -6.0169e-04,\n",
      "         8.5928e-04, -1.0477e-04,  1.0479e-03, -2.1876e-04, -8.6635e-04,\n",
      "        -2.4738e-05,  0.0000e+00, -2.3143e-04,  7.5556e-05,  3.9079e-04,\n",
      "         1.3942e-04, -4.8908e-04, -2.2169e-04, -4.9554e-04, -1.7827e-05,\n",
      "         0.0000e+00, -1.2659e-03,  0.0000e+00, -8.4350e-04,  4.0472e-05,\n",
      "         2.3732e-04, -2.3110e-05,  3.7337e-04, -5.7116e-04,  0.0000e+00,\n",
      "        -3.0320e-04,  3.8579e-04,  0.0000e+00, -2.5285e-04,  1.3737e-04,\n",
      "        -3.1686e-04, -3.1202e-04,  2.1175e-04, -9.3343e-04, -4.2396e-04,\n",
      "         1.2142e-05, -2.8262e-04,  6.6992e-06, -3.4153e-04, -8.9704e-05,\n",
      "        -5.9730e-04,  1.7816e-04, -3.7559e-04,  0.0000e+00, -7.9032e-05,\n",
      "        -1.2821e-03, -8.1255e-04,  5.0036e-04,  1.6654e-03, -8.6557e-04,\n",
      "         8.1989e-04, -2.4877e-04, -1.2996e-04, -2.1290e-04,  5.3452e-04,\n",
      "         7.9760e-04,  1.3309e-04, -3.3973e-04, -1.9988e-04, -7.0924e-04,\n",
      "        -9.3013e-04, -5.4501e-04, -6.7772e-04, -2.4571e-04,  3.5342e-04,\n",
      "         7.7124e-04,  6.4289e-04,  9.0406e-05, -5.9731e-04,  1.9658e-05,\n",
      "         4.9682e-05, -1.7476e-04,  2.1463e-04,  3.8248e-04,  5.0809e-05,\n",
      "         5.5056e-04,  6.1229e-04,  0.0000e+00, -1.3805e-05, -2.4249e-04,\n",
      "         0.0000e+00,  1.1173e-04,  5.3134e-04, -4.2513e-04, -8.4910e-04],\n",
      "       device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[-0.0579, -0.0227,  0.0894,  ...,  0.0704,  0.0988,  0.0337],\n",
      "        [-0.0622,  0.1222, -0.0634,  ...,  0.1075, -0.0297,  0.0073],\n",
      "        [ 0.0351,  0.0719,  0.0389,  ..., -0.0298,  0.0588, -0.0771],\n",
      "        ...,\n",
      "        [ 0.0212,  0.0973,  0.0085,  ...,  0.0801,  0.0501,  0.0571],\n",
      "        [ 0.1256, -0.0507,  0.0188,  ...,  0.0574,  0.0363,  0.0073],\n",
      "        [-0.0266,  0.0449, -0.0709,  ..., -0.0154, -0.0784, -0.0867]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([[ 9.1832e-04,  6.0527e-04,  0.0000e+00,  ...,  1.9382e-03,\n",
      "          1.7403e-03,  1.3287e-03],\n",
      "        [-4.1892e-04, -3.1236e-04,  0.0000e+00,  ..., -9.7728e-04,\n",
      "         -7.6916e-04, -5.9253e-04],\n",
      "        [-2.1849e-04, -2.0103e-04,  0.0000e+00,  ..., -4.9055e-04,\n",
      "         -4.0517e-04, -3.1570e-04],\n",
      "        ...,\n",
      "        [-3.8439e-05, -7.9711e-05,  0.0000e+00,  ..., -2.6460e-04,\n",
      "         -3.5561e-04, -2.7659e-04],\n",
      "        [-2.5983e-05, -7.3980e-05,  0.0000e+00,  ..., -2.5183e-04,\n",
      "         -1.7773e-04, -1.3822e-04],\n",
      "        [-3.9637e-04, -1.8288e-04,  0.0000e+00,  ..., -6.4140e-04,\n",
      "         -5.1098e-04, -3.6567e-04]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([ 0.0201,  0.0545, -0.0391,  0.0567, -0.0686, -0.0515, -0.0459, -0.0369,\n",
      "         0.0156,  0.0204,  0.0349, -0.0250,  0.0521, -0.0410, -0.0135, -0.0256,\n",
      "         0.0223, -0.0204, -0.0056, -0.0063,  0.0877, -0.0091, -0.0647, -0.0406,\n",
      "         0.0477,  0.0914,  0.0384,  0.0233, -0.0573,  0.0769,  0.0566,  0.0458],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([ 0.0031, -0.0010, -0.0007,  0.0008,  0.0013, -0.0030, -0.0022, -0.0013,\n",
      "         0.0012,  0.0017,  0.0007, -0.0009, -0.0027, -0.0021, -0.0013, -0.0009,\n",
      "         0.0006, -0.0005, -0.0007, -0.0017,  0.0009,  0.0027,  0.0012,  0.0001,\n",
      "         0.0005,  0.0011, -0.0005,  0.0003, -0.0001, -0.0006, -0.0002, -0.0017],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "challenging-apparel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Linear(in_features=32, out_features=100, bias=True)>\n"
     ]
    }
   ],
   "source": [
    "inp = torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "royal-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import unfold\n",
    "class relu(object) :\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, input) :\n",
    "        self.input = input\n",
    "        self.positif_mask = (input > 0)\n",
    "        return self.positif_mask*(input)\n",
    "    def backward(self, gradwrtoutput ) :\n",
    "        self.input.grad = self.positif_mask.int()*gradwrtoutput\n",
    "        print('Our backward: ', self.input.grad)\n",
    "    def param(self) :\n",
    "        return []\n",
    "\n",
    "class sigmoid(object) :\n",
    "    def forward(self, input) :\n",
    "        self.input = input\n",
    "        self.output = 1/(1 + math.e**(-input))\n",
    "        return  self.output\n",
    "    def backward(self, gradwrtoutput ) :\n",
    "        self.input.grad = self.output * (1-self.output) * gradwrtoutput\n",
    "    def param(self) :\n",
    "        return []\n",
    "\n",
    "class convolution(object):\n",
    "    def __init__(self, inp_channels, out_channels, kernelsize = (3,3), stride=1):\n",
    "        self.kernel = torch.rand(kernelsize)\n",
    "        self.kernelsize = kernelsize\n",
    "        self.stride = stride\n",
    "        self.inp_channels = inp_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        bs = input.size(0)\n",
    "#         assert self.inp_channels == input.size(1):\n",
    "#             raise AssertionError('The number of input channel is not right')\n",
    "#         print(((input.size(0) - self.kernel.size(0) +1)/(self.stride)))\n",
    "        h = torch.tensor((input.size(-2) - self.kernel.size(0) +1)/(self.stride)).floor().int()\n",
    "#         print(torch.tensor((input.size(-1) - self.kernel.size(0) +1)))\n",
    "        w = torch.tensor((input.size(1) - self.kernel.size(1) +1)/(self.stride)).floor().int()\n",
    "        unf = unfold(inp, kernel_size=self.kernelsize)\n",
    "        conv = kernel.view(1, -1) @ unf\n",
    "#         print(conv.view(1,1, 2, 2))\n",
    "#         print(h, w)\n",
    "        return conv.view(1, 1, h, w)\n",
    "\n",
    "    def backward(self, input):\n",
    "        pass\n",
    "    def param(self) :\n",
    "        return [self.kernel]\n",
    "    \n",
    "class mse(object):\n",
    "    def forward(self, input, target):\n",
    "        self.input = input\n",
    "        self.target = target\n",
    "        return (input - target).pow(2).mean(dim=[1, 2, 3]).sum()\n",
    "    def backward(self, gradwrtoutput):\n",
    "        self.input.grad = 2*(self.input-self.target)/9\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "national-disposal",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tensor([-3.2310, -2.0362,  1.8063,  2.1106, -2.0957])\n",
      "output:  tensor([-0.0000, -0.0000, 1.8063, 2.1106, -0.0000], grad_fn=<MulBackward0>)\n",
      "output_comp:  tensor([0.0000, 0.0000, 1.8063, 2.1106, 0.0000], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mse() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-287704a8f5e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmse_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mloss_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_comp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_comp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mse() takes no arguments"
     ]
    }
   ],
   "source": [
    "inp = torch.normal(torch.zeros(5), torch.ones(5)*2)\n",
    "print('input: ', inp)\n",
    "tar = torch.round(inp).requires_grad_(True)\n",
    "model= relu()\n",
    "model_comp = torch.nn.ReLU()\n",
    "inp\n",
    "inp.requires_grad_(True)\n",
    "inp_comp = inp.clone()\n",
    "out = model.forward(inp)\n",
    "out_comp = model_comp(inp)\n",
    "print('output: ', out)\n",
    "print('output_comp: ', out_comp)\n",
    "\n",
    "mse_comp = torch.nn.MSELoss()\n",
    "loss = mse(out,tar)\n",
    "loss_comp = mse_comp(out_comp,tar)\n",
    "print('loss: ', loss)\n",
    "print('loss_comp: ', loss_comp)\n",
    "\n",
    "\n",
    "print(model.backward(loss))\n",
    "loss_comp.backward()\n",
    "print(inp_comp.grad)\n",
    "print(out_comp.grad)\n",
    "# torch.autograd.grad(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "valued-korea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.3525, -0.0791, -0.4124],\n",
      "          [-0.7524, -0.0326, -0.4163],\n",
      "          [-0.0993,  0.2336,  0.3236]]]])\n",
      "tensor([[[[-0.6587,  1.3150,  1.1016],\n",
      "          [ 1.3700,  0.4632, -0.3212],\n",
      "          [ 0.4432,  0.8230,  1.0158]]]], requires_grad=True)\n",
      "tensor([[[[-0.0000, 1.3150, 1.1016],\n",
      "          [1.3700, 0.4632, -0.0000],\n",
      "          [0.4432, 0.8230, 1.0158]]]], grad_fn=<MulBackward0>)\n",
      "tensor(1.1560, grad_fn=<SumBackward0>)\n",
      "tensor(1.1560, grad_fn=<MseLossBackward0>)\n",
      "Our backward:  tensor([[[[-0.0000, 0.3098, 0.3364],\n",
      "          [0.4716, 0.1102, 0.0000],\n",
      "          [0.1206, 0.1310, 0.1538]]]], grad_fn=<MulBackward0>)\n",
      "tensor([[[[-0.0000, 0.3098, 0.3364],\n",
      "          [0.4716, 0.1102, 0.0000],\n",
      "          [0.1206, 0.1310, 0.1538]]]], grad_fn=<MulBackward0>)\n",
      "tensor([[[[0.0000, 0.3098, 0.3364],\n",
      "          [0.4716, 0.1102, 0.0000],\n",
      "          [0.1206, 0.1310, 0.1538]]]])\n"
     ]
    }
   ],
   "source": [
    "MSE = nn.MSELoss()\n",
    "\n",
    "target = torch.randn(1, 1, 3, 3)\n",
    "print(target)\n",
    "\n",
    "input = torch.randn(1, 1, 3, 3, requires_grad=True)\n",
    "input2 = input.detach().requires_grad_(True)\n",
    "\n",
    "print(input)\n",
    "# print(input2)\n",
    "model = relu()\n",
    "model2 = torch.nn.ReLU()\n",
    "\n",
    "out = model.forward(input)\n",
    "out2 = model2.forward(input2)\n",
    "\n",
    "print(out)\n",
    "# print(out2)\n",
    "my_mse = mse()\n",
    "loss = my_mse.forward(out, target)\n",
    "loss2 = MSE(out2, target)\n",
    "\n",
    "print(loss)\n",
    "print(loss2)\n",
    "my_mse.backward(loss)\n",
    "model.backward(my_mse.input.grad)\n",
    "\n",
    "loss2.backward()\n",
    "\n",
    "# print(model.input.grad)\n",
    "\n",
    "print(input.grad)\n",
    "print(input2.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "limiting-update",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/idiap/user/lcoppieters/anaconda3/envs/pytorch180/lib/python3.8/site-packages/torch/_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272128894/work/build/aten/src/ATen/core/TensorBody.h:417.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "out2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "likely-proxy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcbfae12b50>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(inp,out, '.')\n",
    "plt.plot(inp,tar, '.')\n",
    "plt.plot(inp, loss, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "corresponding-wallace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "imperial-candy",
   "metadata": {},
   "source": [
    "(a > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "liked-reputation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a > 0).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-adjustment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
