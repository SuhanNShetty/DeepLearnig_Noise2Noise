{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba34b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4397,  0.2831,  1.5650, -0.5245, -2.0008,  2.2580, -0.0792, -0.3956,\n",
      "         -0.0845,  0.1205,  1.9671,  1.1400,  0.6991,  1.2292,  0.2043, -0.0662,\n",
      "         -0.2540, -1.3839,  0.3893,  0.4615,  0.6654,  0.5382,  0.5478,  1.1590,\n",
      "         -0.8607]])\n",
      "tensor([[-0.4397,  0.2831,  1.5650, -0.5245, -2.0008],\n",
      "        [ 2.2580, -0.0792, -0.3956, -0.0845,  0.1205],\n",
      "        [ 1.9671,  1.1400,  0.6991,  1.2292,  0.2043],\n",
      "        [-0.0662, -0.2540, -1.3839,  0.3893,  0.4615],\n",
      "        [ 0.6654,  0.5382,  0.5478,  1.1590, -0.8607]])\n",
      "tensor([[-0.8607,  1.1590,  0.5478,  0.5382,  0.6654],\n",
      "        [ 0.4615,  0.3893, -1.3839, -0.2540, -0.0662],\n",
      "        [ 0.2043,  1.2292,  0.6991,  1.1400,  1.9671],\n",
      "        [ 0.1205, -0.0845, -0.3956, -0.0792,  2.2580],\n",
      "        [-2.0008, -0.5245,  1.5650,  0.2831, -0.4397]])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "from torch import empty , cat , arange\n",
    "from torch.nn.functional import fold , unfold\n",
    "\n",
    "kernel = empty((5,5)).normal_()\n",
    "print(kernel.view(1,-1))\n",
    "print(kernel)\n",
    "print(kernel.flip((0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e85a7345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2661, -0.5691, -0.1831],\n",
      "        [-0.8653, -0.5603, -0.5318],\n",
      "        [-0.2112,  0.7639, -0.5779]])\n",
      "tensor([[-0.5779,  0.7639, -0.2112],\n",
      "        [-0.5318, -0.5603, -0.8653],\n",
      "        [-0.1831, -0.5691,  0.2661]])\n"
     ]
    }
   ],
   "source": [
    "kernel = empty((3,3)).normal_()\n",
    "print(kernel)\n",
    "print(kernel.flip(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24efb6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class relu(object) :\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, input) :\n",
    "        self.input = input\n",
    "        self.positif_mask = (input > 0)\n",
    "        return self.positif_mask*(input)\n",
    "    def backward(self, gradwrtoutput) :\n",
    "        self.input.grad = self.positif_mask.int()*gradwrtoutput\n",
    "        return self.input.grad\n",
    "    def param(self) :\n",
    "        return []\n",
    "\n",
    "class sigmoid(object) :\n",
    "    def forward(self, input) :\n",
    "        self.input = input\n",
    "        self.output = 1/(1 + math.e**(-input))\n",
    "        return  self.output\n",
    "    def backward(self, gradwrtoutput ) :\n",
    "        self.input.grad = self.output * (1-self.output) * gradwrtoutput\n",
    "        return self.input.grad\n",
    "    def param(self) :\n",
    "        return []\n",
    "\n",
    "class convolution(object):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size = (3,3), padding = 0, stride = 1, use_bias = False):\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.kernel_size = kernel_size\n",
    "        self.k_1 = self.kernel_size[0]\n",
    "        self.k_2 = self.kernel_size[1]\n",
    "        self.use_bias = use_bias\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.kernel = empty(out_ch, in_ch, self.k_1, self.k_2).normal_()\n",
    "        self.bias = empty(out_ch).normal_() if use_bias else 0 *empty(out_ch)\n",
    "        \n",
    "    def forward(self, x):   \n",
    "        self.x = x\n",
    "        self.batch_size = x.size(0)\n",
    "        X_unf = unfold(x, kernel_size=(self.k_1, self.k_2), padding = self.padding, stride = self.stride)\n",
    "        K_expand = self.kernel.view(self.out_ch, -1)\n",
    "        O_expand = K_expand @ X_unf\n",
    "        s1 = math.ceil((x.size(-2)-self.k_1+1+self.padding*2)/(self.stride))\n",
    "        s2 = math.ceil((x.size(-1)-self.k_2+1+self.padding*2)/(self.stride))\n",
    "\n",
    "        O = O_expand.view(self.batch_size, self.out_ch, s1, s2)\n",
    "        return O + self.bias.view(1, -1, 1, 1) if self.use_bias else O\n",
    "    \n",
    "    def backward(self, gradwrtoutput):\n",
    "        kernel_back = self.kernel.flip(-2, -1).transpose(0,1)\n",
    "        s1 = self.x.size(-2)\n",
    "        s2 = self.x.size(-1)\n",
    "        \n",
    "        # backward wrt input\n",
    "        M = self.get_M(s1-self.k_1 + 1 + self.padding*2)\n",
    "        dL_dO = (M.transpose(0,1) @ gradwrtoutput) @ M\n",
    "\n",
    "        dL_dO_unf = unfold(dL_dO, kernel_size=(k_1, k_2), padding = (k_1 - 1 - self.padding, k_2-1- self.padding), stride = 1)\n",
    "        dO_dX_exp = kernel_back.reshape(self.in_ch, -1)\n",
    "        dL_dX_exp = dO_dX_exp @ dL_dO_unf\n",
    "        dL_dX = dL_dX_exp.view(self.batch_size, self.in_ch, s1, s2)\n",
    "        \n",
    "        self.dL_dO = dL_dO.transpose(0,1) # K\n",
    "        self.dO_dF = self.x.view(self.in_ch, self.batch_size, s1, s2).transpose(0,1) # X\n",
    "        \n",
    "        # backward wrt weights\n",
    "        dL_dO_unf_F = self.dL_dO.reshape(self.out_ch, -1)\n",
    "        dO_dF_exp = unfold(self.dO_dF, kernel_size = (s1 - self.k_1 +1 + self.padding*2, s2 - self.k_2 +1 + self.padding*2), padding = self.padding, stride = 1)\n",
    "        dL_dF_exp = dL_dO_unf_F @ dO_dF_exp\n",
    "        dL_dF = dL_dF_exp.transpose(0,1).view(self.kernel.size())\n",
    "        \n",
    "        # backward wrt bias\n",
    "        if self.use_bias:\n",
    "            dL_dO_exp = self.dL_dO.reshape(self.out_ch, -1)\n",
    "            dO_dB_exp = torch.ones(self.batch_size * (s1 - self.k_1 +1 + self.padding*2) * (s2 - self.k_2 +1 + self.padding*2))\n",
    "            dL_dB = dL_dO_exp @ dO_dB_exp\n",
    "        else:\n",
    "            dL_dB = None\n",
    "        return dL_dX, dL_dF, dL_dB\n",
    "    \n",
    "    def get_M(self, N):\n",
    "        diag = empty(N)\n",
    "        eye_N = (diag == diag).int()\n",
    "        print(eye_N.diag()[range(0,N,self.stride)])\n",
    "        return eye_N.diag()[range(0,N,self.stride)]\n",
    "        \n",
    "    def param(self) :\n",
    "        return [self.kernel, self.bias]\n",
    "    \n",
    "\n",
    "    \n",
    "class mse(object):\n",
    "    def forward(self, input, target):\n",
    "        self.input = input\n",
    "        self.target = target\n",
    "        return (input - target).pow(2).mean()\n",
    "    def backward(self, gradwrtoutput):\n",
    "        self.input.grad = 2*(self.input-self.target)/(self.input.size(-3)*self.input.size(-2)*self.input.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08b27474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7388, -0.0000, -0.0000, 0.1223, 0.4201],\n",
      "          [0.6851, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [0.6297, -0.0000, 0.5666, -0.0000, 1.8904],\n",
      "          [1.1787, -0.0000, 1.9886, 0.9957, -0.0000],\n",
      "          [0.1553, -0.0000, -0.0000, 0.0232, 0.5207]]]])\n",
      "tensor([[[[0.7388, -0.0000, -0.0000, 0.1223, 0.4201],\n",
      "          [0.6851, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "          [0.6297, -0.0000, 0.5666, -0.0000, 1.8904],\n",
      "          [1.1787, -0.0000, 1.9886, 0.9957, -0.0000],\n",
      "          [0.1553, -0.0000, -0.0000, 0.0232, 0.5207]]]])\n"
     ]
    }
   ],
   "source": [
    "input = empty((1,1,5,5)).normal_()\n",
    "test = relu()\n",
    "print(test.forward(input))\n",
    "print(test.backward(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "964d2bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6767, 0.2419, 0.3408, 0.5305, 0.6035],\n",
      "          [0.6649, 0.4579, 0.2193, 0.4160, 0.4553],\n",
      "          [0.6524, 0.3493, 0.6380, 0.4464, 0.8688],\n",
      "          [0.7647, 0.2813, 0.8796, 0.7302, 0.3238],\n",
      "          [0.5388, 0.3343, 0.2946, 0.5058, 0.6273]]]])\n",
      "tensor([[[[ 0.1616, -0.2095, -0.1482,  0.0305,  0.1005],\n",
      "          [ 0.1526, -0.0419, -0.2174, -0.0825, -0.0445],\n",
      "          [ 0.1428, -0.1414,  0.1309, -0.0532,  0.2155],\n",
      "          [ 0.2121, -0.1896,  0.2106,  0.1962, -0.1612],\n",
      "          [ 0.0386, -0.1533, -0.1815,  0.0058,  0.1217]]]])\n"
     ]
    }
   ],
   "source": [
    "test = sigmoid()\n",
    "print(test.forward(input))\n",
    "print(test.backward(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac88dc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.6421,  2.2281,  0.0636],\n",
      "          [ 0.0623,  3.3166,  6.1868],\n",
      "          [ 0.9785, -3.6024, -0.4413]],\n",
      "\n",
      "         [[-1.8030,  3.1638,  1.1656],\n",
      "          [-5.7831,  2.2954, -2.4630],\n",
      "          [-3.3882,  0.8357,  0.5098]],\n",
      "\n",
      "         [[-1.3934,  3.8067, -1.5470],\n",
      "          [-7.6987,  3.5430,  0.8334],\n",
      "          [-4.5797, -3.2027, -3.8037]]]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [0, 0, 1]], dtype=torch.int32) 3\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5x5 and 3x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m test \u001b[38;5;241m=\u001b[39m convolution(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(test\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28minput\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[1;32mIn [72]\u001b[0m, in \u001b[0;36mconvolution.backward\u001b[1;34m(self, gradwrtoutput)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# backward wrt input\u001b[39;00m\n\u001b[0;32m     56\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_M(s1\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m dL_dO \u001b[38;5;241m=\u001b[39m (\u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgradwrtoutput\u001b[49m) \u001b[38;5;241m@\u001b[39m M\n\u001b[0;32m     59\u001b[0m dL_dO_unf \u001b[38;5;241m=\u001b[39m unfold(dL_dO, kernel_size\u001b[38;5;241m=\u001b[39m(k_1, k_2), padding \u001b[38;5;241m=\u001b[39m (k_1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, k_2\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding), stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     60\u001b[0m dO_dX_exp \u001b[38;5;241m=\u001b[39m kernel_back\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_ch, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (5x5 and 3x3)"
     ]
    }
   ],
   "source": [
    "test = convolution(1,3)\n",
    "print(test.forward(input))\n",
    "print(test.backward(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "df324bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = empty(5).normal_().diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "259abdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0959,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  1.1059,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -1.5449,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, -0.5452,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4348]])\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9de0de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
