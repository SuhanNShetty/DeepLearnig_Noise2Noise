{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "geological-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import empty , cat , arange\n",
    "from torch.nn.functional import fold , unfold\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interested-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convolution(object):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size = (3,3), padding = 0, stride = 1, use_bias = False):\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.kernel_size = kernel_size\n",
    "        self.k_1 = self.kernel_size[0]\n",
    "        self.k_2 = self.kernel_size[1]\n",
    "        self.use_bias = use_bias\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.kernel = empty(out_ch, in_ch, self.k_1, self.k_2).normal_()\n",
    "        self.bias = empty(out_ch).normal_() if use_bias else 0 *empty(out_ch)\n",
    "        \n",
    "    def forward(self, x):   \n",
    "        self.x = x\n",
    "        self.batch_size = x.size(0)\n",
    "        X_unf = unfold(x, kernel_size=(self.k_1, self.k_2), padding = self.padding, stride = self.stride)\n",
    "        K_expand = self.kernel.view(self.out_ch, -1)\n",
    "        O_expand = K_expand @ X_unf\n",
    "        s1 = math.ceil((x.size(-2)-self.k_1+1+self.padding*2)/(self.stride))\n",
    "        s2 = math.ceil((x.size(-1)-self.k_2+1+self.padding*2)/(self.stride))\n",
    "\n",
    "        O = O_expand.view(self.batch_size, self.out_ch, s1, s2)\n",
    "        return O + self.bias.view(1, -1, 1, 1) if self.use_bias else O\n",
    "    \n",
    "    def backward(self, gradwrtoutput):\n",
    "        kernel_back = self.kernel.flip(-2, -1).transpose(0,1)\n",
    "        s1 = self.x.size(-2)\n",
    "        s2 = self.x.size(-1)\n",
    "        \n",
    "        # backward wrt input\n",
    "        M = self.get_M(s1-self.k_1 + 1 + self.padding*2)\n",
    "        dL_dO = (M.transpose(0,1) @ gradwrtoutput) @ M\n",
    "\n",
    "        dL_dO_unf = unfold(dL_dO, kernel_size=(self.k_1, self.k_2), padding = (self.k_1 - 1 - self.padding, self.k_2-1- self.padding), stride = 1)\n",
    "        dO_dX_exp = kernel_back.reshape(self.in_ch, -1)\n",
    "        dL_dX_exp = dO_dX_exp @ dL_dO_unf\n",
    "        dL_dX = dL_dX_exp.view(self.batch_size, self.in_ch, s1, s2)\n",
    "        \n",
    "        self.dL_dO = dL_dO.transpose(0,1) # K\n",
    "        self.dO_dF = self.x.view(self.in_ch, self.batch_size, s1, s2).transpose(0,1) # X\n",
    "        \n",
    "        # backward wrt weights\n",
    "        dL_dO_unf_F = self.dL_dO.reshape(self.out_ch, -1)\n",
    "        dO_dF_exp = unfold(self.dO_dF, kernel_size = (s1 - self.k_1 +1 + self.padding*2, s2 - self.k_2 +1 + self.padding*2), padding = self.padding, stride = 1)\n",
    "        dL_dF_exp = dL_dO_unf_F @ dO_dF_exp.view(self.in_ch,-1,self.k_1*self.k_2)\n",
    "        dL_dF = dL_dF_exp.transpose(0,1).view(self.kernel.size())\n",
    "        \n",
    "        # backward wrt bias\n",
    "        if self.use_bias:\n",
    "            dL_dO_exp = self.dL_dO.reshape(self.out_ch, -1)\n",
    "            dO_dB_exp = torch.ones(self.batch_size * (s1 - self.k_1 +1 + self.padding*2) * (s2 - self.k_2 +1 + self.padding*2))\n",
    "            dL_dB = dL_dO_exp @ dO_dB_exp\n",
    "        else:\n",
    "            dL_dB = None\n",
    "        self.dL_dX = dL_dX\n",
    "        self.dL_dF = dL_dF\n",
    "        self.dL_dB = dL_dB\n",
    "        return dL_dX, dL_dF, dL_dB\n",
    "    \n",
    "    def get_M(self, N):\n",
    "        diag = empty(N)\n",
    "        eye_N = (diag == diag).float().diag()\n",
    "        return eye_N[range(0,N,self.stride)]\n",
    "        \n",
    "    def param(self) :\n",
    "        return [self.kernel, self.bias]\n",
    "\n",
    "\n",
    "    \n",
    "class convolution2(object):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size = (3,3), padding = 0, stride = 1, use_bias = False):\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.kernel_size = kernel_size\n",
    "        self.k = self.kernel_size[0]\n",
    "        self.use_bias = use_bias\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.kernel = torch.empty(out_ch, in_ch, self.k, self.k).normal_()\n",
    "        self.bias = torch.empty(out_ch).normal_() if use_bias else torch.zeros(out_ch)\n",
    "        \n",
    "    def forward(self, x):   \n",
    "        \n",
    "        self.batch_size = x.size(0)\n",
    "        self.s_in = x.size(-1)\n",
    "        self.s_out = torch.tensor(x.size(-2)-self.k+1+self.padding*2).div(self.stride).ceil().int()\n",
    "        \n",
    "        X_unf = unfold(x, kernel_size=(self.k, self.k), padding = self.padding, stride = self.stride)\n",
    "        \n",
    "        self.X_unf = X_unf\n",
    "    \n",
    "        K_expand = self.kernel.view(self.out_ch, -1)\n",
    "        O_expand = K_expand @ X_unf\n",
    "        print('X_unf: ', X_unf.size())\n",
    "        print('K_expand: ', K_expand.size())\n",
    "        print('O_expand: ', O_expand.size())\n",
    "        \n",
    "        O = O_expand.view(self.batch_size, self.out_ch, self.s_out, self.s_out)\n",
    "        return O + self.bias.view(1, -1, 1, 1) if self.use_bias else O\n",
    "    \n",
    "    def backward(self, gradwrtoutput):\n",
    "        dL_dO = gradwrtoutput\n",
    "        dO_dX = self.kernel\n",
    "\n",
    "        dL_dO_exp = dL_dO.reshape(self.batch_size, self.out_ch, -1)\n",
    "        dO_dX_exp = dO_dX.reshape(self.out_ch,-1).transpose(0,1)\n",
    "        dL_dO_unf = dO_dX_exp @ dL_dO_exp\n",
    "        print('dL_dO_exp: ', dL_dO_exp.size())\n",
    "        print('dO_dX_exp: ', dO_dX_exp.size())\n",
    "        print('dL_dO_unf: ',dL_dO_unf.size())\n",
    "        self.dL_dO_unf = dL_dO_unf\n",
    "        dL_dO = fold(dL_dO_unf, kernel_size = (self.k, self.k), padding = self.padding, stride = self.stride, output_size = (self.s_in, self.s_in))\n",
    "        \n",
    "        \n",
    "        # dL_dO_exp_F = dL_dO.reshape(bs, -1).transpose(0,1)\n",
    "        # dO_dF_unf = self.X_unf.transpose(0,1)\n",
    "        # print(dL_dO_exp_F.size(), dO_dF_unf.size())\n",
    "        # dL_dF_exp = dL_dO_exp_F @ dO_dF_unf\n",
    "        # dL_dF = dL_dF_exp.view(self.in_ch, self.out_ch, self.k, self.k).transpose(0,1)\n",
    "        \n",
    "        return dL_dO\n",
    "# #         kernel_back = self.kernel.flip(-2, -1).transpose(0,1)\n",
    "#         s1 = self.x.size(-2)\n",
    "#         s2 = self.x.size(-1)\n",
    "        \n",
    "        \n",
    "#         # backward wrt input\n",
    "#         M = self.get_M(s1-k_1 + 1 + self.padding*2)\n",
    "#         dL_dO = (M.transpose(0,1) @ gradwrtoutput) @ M\n",
    "\n",
    "#         dL_dO_unf   = unfold(dL_dO, kernel_size=(k_1, k_2), padding = (k_1 - 1 - self.padding, k_2-1- self.padding), stride = 1)\n",
    "#         dO_dX_exp   = kernel_back.reshape(self.in_ch, -1)\n",
    "#         dL_dX_exp   = dO_dX_exp @ dL_dO_unf\n",
    "#         dL_dX       = dL_dX_exp.view(self.batch_size, self.in_ch, s1, s2)\n",
    "        \n",
    "#         # backward wrt weights\n",
    "#         self.dL_dO  = dL_dO.transpose(0,1) \n",
    "#         self.dO_dF  = self.x.view(self.in_ch, self.batch_size, s1, s2).transpose(0,1) \n",
    "        \n",
    "#         dL_dO_unf_F = self.dL_dO.reshape(self.out_ch, -1)\n",
    "#         dO_dF_exp   = unfold(self.dO_dF, kernel_size = (s1 - self.k_1 +1 + self.padding*2, s2 - self.k_2 +1 + self.padding*2), padding = self.padding, stride = 1)\n",
    "#         dL_dF_exp   = dL_dO_unf_F @ dO_dF_exp\n",
    "#         self.dL_dF       = dL_dF_exp.transpose(0,1).view(self.kernel.size())\n",
    "        \n",
    "#         # backward wrt bias\n",
    "#         if self.use_bias:\n",
    "#             dL_dO_exp = self.dL_dO.reshape(self.out_ch, -1)\n",
    "#             dO_dB_exp = torch.ones(self.batch_size * (s1 - self.k_1 +1 + self.padding*2) * (s2 - self.k_2 +1 + self.padding*2))\n",
    "#             self.dL_dB = dL_dO_exp @ dO_dB_exp\n",
    "#         else:\n",
    "#             self.dL_dB = None\n",
    "        \n",
    "#         return dL_dX, self.dL_dF, self.dL_dB\n",
    "    \n",
    "    def get_M(self, N):\n",
    "        return torch.eye(N)[range(0,N,self.stride)]\n",
    "        \n",
    "    def param(self) :\n",
    "        return ((self.kernel, self.dL_dF), (self.bias, self.dL_dB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "entertaining-mills",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_unf:  torch.Size([2, 18, 16])\n",
      "K_expand:  torch.Size([4, 18])\n",
      "O_expand:  torch.Size([2, 4, 16])\n",
      "same output of conv:  tensor(2.8270e-05, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Initial parameters\n",
    "s_1, s_2 = 7,7\n",
    "k_1, k_2 = 3,3\n",
    "bs = 2\n",
    "ch_in, ch_out = 2, 4\n",
    "stride = 2\n",
    "padding = 1\n",
    "# input tensor \n",
    "X = torch.empty(bs, ch_in, s_1, s_2).normal_().requires_grad_()\n",
    "X_copy = X.clone().detach().requires_grad_()\n",
    "\n",
    "# initialize convolution moduls\n",
    "conv = convolution2(ch_in, ch_out, kernel_size = (k_1, k_2), padding = padding, use_bias=True, stride = stride)\n",
    "\n",
    "# get weigts and bias\n",
    "F = conv.kernel\n",
    "B = conv.bias\n",
    "F.requires_grad_()\n",
    "B.requires_grad_()\n",
    "\n",
    "# forward\n",
    "out = conv.forward(X)\n",
    "out_compare = torch.nn.functional.conv2d(X_copy, F, bias = B, stride = stride, padding=padding)\n",
    "\n",
    "# backward\n",
    "#dL_dX, dL_dF, dL_dB = conv.backward(out/out)\n",
    "#out_compare.backward(out_compare/out_compare)\n",
    "\n",
    "\n",
    "\n",
    "print('same output of conv: ', (out_compare - out).abs().sum()) \n",
    "#print('same input gradient: ', (X_copy.grad - dL_dX).abs().sum())\n",
    "#print('same weigth gradient: ',(F.grad-dL_dF).abs().sum() )\n",
    "#print('same bias gradient: ',(B.grad-dL_dB).abs().sum() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1bd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
