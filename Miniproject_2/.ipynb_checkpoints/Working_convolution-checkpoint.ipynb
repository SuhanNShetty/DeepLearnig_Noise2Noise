{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "geological-journalism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  torch.Size([2, 4, 5, 5])\n",
      "Passed the output and gradient test\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import fold , unfold\n",
    "import matplotlib.pyplot as plt\n",
    "im_1, im_2 = 5, 5\n",
    "k_1, k_2 = 3, 3\n",
    "bs = 2\n",
    "ch_in, ch_out = 4, 3\n",
    "X = torch.empty(bs, ch_in, im_1, im_2).normal_().requires_grad_()\n",
    "print('X: ', X.size())\n",
    "F = torch.empty(ch_out, ch_in, k_1, k_2).normal_()\n",
    "O = torch.nn.functional.conv2d(X, F)\n",
    "X_unf = unfold(X, kernel_size=(k_1, k_2), padding = 0)\n",
    "F_expand = F.view(ch_out, -1)\n",
    "O_expand = F_expand @ X_unf\n",
    "\n",
    "\n",
    "out_comp = O_expand.view(bs, ch_out, im_1 - k_1 + 1, im_2 - k_2 + 1)\n",
    "L = O*2\n",
    "\n",
    "dL_dO = L/O\n",
    "F_back = F.flip(-1, -2).transpose(0,1)\n",
    "dL_dX = torch.nn.functional.conv2d(dL_dO, F_back, padding =( k_1 - 1,k_2-1) )#/(bs * ch_out*(im_1 - k_1 + 1) * ( im_2 - k_2 +1))\n",
    "\n",
    "X_unf = unfold(dL_dO, kernel_size=(k_1, k_2), padding = (k_1 - 1,k_2-1))\n",
    "F_expand = F_back.reshape(ch_in, -1)\n",
    "\n",
    "O_expand = F_expand @ X_unf\n",
    "L.sum().backward()\n",
    "\n",
    "\n",
    "torch.testing.assert_allclose(O, out_comp)\n",
    "torch.testing.assert_allclose(dL_dX, X.grad)\n",
    "\n",
    "print('Passed the output and gradient test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "interested-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convolution(object):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size = (3,3), padding = 0, use_bias = False):\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.kernel_size = kernel_size\n",
    "        self.k_1 = self.kernel_size[0]\n",
    "        self.k_2 = self.kernel_size[1]\n",
    "        \n",
    "        self.padding = padding\n",
    "        self.kernel = torch.empty(out_ch, in_ch, self.k_1, self.k_2).normal_()\n",
    "        self.bias = torch.empty(out_ch).normal_() if use_bias else torch.zeros(out_ch)\n",
    "        \n",
    "    def forward(self, x):   \n",
    "        self.x = x\n",
    "        self.batch_size = x.size(0)\n",
    "        X_unf = unfold(x, kernel_size=(self.k_1, self.k_2), padding = self.padding)\n",
    "        K_expand = self.kernel.view(self.out_ch, -1)\n",
    "        O_expand = K_expand @ X_unf\n",
    "        \n",
    "        s1 = x.size(-2)-self.k_1+1+self.padding*2\n",
    "        s2 = x.size(-1)-self.k_2+1+self.padding*2\n",
    "        return O_expand.view(self.batch_size, self.out_ch, s1, s2)\n",
    "    \n",
    "    def backward(self, gradwrtoutput):\n",
    "        kernel_back = self.kernel.flip(-2, -1).transpose(0,1)\n",
    "        s1 = self.x.size(-2)\n",
    "        s2 = self.x.size(-1)\n",
    "        \n",
    "        dL_dO_unf = unfold(gradwrtoutput, kernel_size=(k_1, k_2), padding = (k_1 - 1, k_2-1))\n",
    "        dO_dX_exp = kernel_back.reshape(self.in_ch, -1)\n",
    "        dL_dX_exp = dO_dX_exp @ dL_dO_unf\n",
    "        dL_dX = dL_dX_exp.view(self.batch_size, self.in_ch, s1, s2)\n",
    "        \n",
    "        self.dL_dO = gradwrtoutput.transpose(0,1) # K\n",
    "        self.dO_dF = self.x.view(self.in_ch, self.batch_size, s1, s2).transpose(0,1) # X\n",
    "        \n",
    "        dL_dO_unf_F = self.dL_dO.reshape(self.out_ch, -1)\n",
    "        dO_dF_exp = unfold(self.dO_dF, kernel_size = (s1 - self.k_1 +1 + self.padding, s2 - self.k_2 +1 + self.padding), padding = self.padding)\n",
    "        dL_dF_exp = dL_dO_unf_F @ dO_dF_exp\n",
    "        dL_dF = dL_dF_exp.transpose(0,1).view(self.kernel.size())\n",
    "\n",
    "        return dL_dX, dL_dF\n",
    "    \n",
    "    def param(self) :\n",
    "        return [self.kernel]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "entertaining-mills",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'zeros_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-338-d05dceec241f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-337-555b1163f6f9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_ch, out_ch, kernel_size, padding, use_bias)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_ch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_ch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_ch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_bias\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'zeros_'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import fold , unfold\n",
    "im_1, im_2 = 4, 4\n",
    "k_1, k_2 = 3,3\n",
    "bs = 2\n",
    "ch_in, ch_out = 2, 4\n",
    "\n",
    "X = torch.empty(bs, ch_in, im_1, im_2).normal_().requires_grad_()\n",
    "X_copy = X.clone().detach().requires_grad_()\n",
    "\n",
    "conv = convolution(ch_in, ch_out, kernel_size = (k_1, k_2), padding = 0)\n",
    "F = conv.kernel\n",
    "F.requires_grad_(True)\n",
    "\n",
    "out = conv.forward(X)\n",
    "out_compare = torch.nn.functional.conv2d(X_copy, F)\n",
    "\n",
    "dL_dX, dL_dF = conv.backward(out/out)\n",
    "out_compare.backward(out_compare/out_compare)\n",
    "\n",
    "\n",
    "\n",
    "print('same output of conv: ', (out_compare - out).abs().sum()) \n",
    "print('same input gradient: ', (X_copy.grad - dL_dX).abs().sum())\n",
    "print('same kernel gradient: ',(F.grad-dL_dF).abs().sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "fifth-cheat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]]]])\n",
      "tensor([[[[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2482,  1.4429,  0.2975],\n",
      "          [ 2.4374,  1.3758, -1.8613],\n",
      "          [-2.0750, -1.2036, -0.4597]],\n",
      "\n",
      "         [[ 1.8387,  3.1812, -0.0757],\n",
      "          [ 4.0833,  3.4628,  0.6435],\n",
      "          [-1.7010, -2.5746,  1.1417]]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(F.grad)\n",
    "print(dL_dF)\n",
    "print(dL_dF.transpose(0,1))\n",
    "print(dL_dF.view(dL_dF.size(0), dL_dF.size(1), dL_dF.size(2), dL_dF.size(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "involved-lesson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 2, 2])\n",
      "torch.Size([2, 2, 4, 4])\n",
      "kernel:  torch.Size([4, 2, 2, 2])\n",
      "input:  torch.Size([2, 2, 4, 4])\n",
      "torch.Size([2, 8, 9])\n",
      "torch.Size([4, 8])\n",
      "2 2\n",
      "torch.Size([4, 2, 3, 3])\n",
      "torch.Size([4, 2, 3, 3])\n",
      "torch.Size([4, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# print(F.grad.size())\n",
    "\n",
    "print(conv.dL_dO.transpose(0,1).size())\n",
    "print(conv.dO_dF.transpose(0,1).size())\n",
    "\n",
    "X = conv.dO_dF\n",
    "K = conv.dL_dO\n",
    "conv_out = torch.nn.functional.conv2d(X, K).transpose(0,1)\n",
    "print('kernel: ',K.size())\n",
    "print('input: ',X.size())\n",
    "X_unf = unfold(X, kernel_size = (2, 2), padding = 0)\n",
    "print(X_unf.size())\n",
    "F_exp = K.reshape(ch_out, -1)\n",
    "print(F_exp.size())\n",
    "print(im_1 - conv.k_1 +1 + conv.padding, im_2 - conv.k_2 + 1 + conv.padding)\n",
    "O_exp = F_exp @ X_unf\n",
    "O = O_exp.view(ch_in, ch_out, k_1, k_2).transpose(0,1)\n",
    "print(O.size())\n",
    "print(conv_out.size())\n",
    "print(conv.kernel.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "upper-status",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "torch.Size([10, 5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "c = torch.nn.Conv2d(5, 10, kernel_size=(3, 3))\n",
    "print(c.bias.size())\n",
    "print(c.weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "pointed-helen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1950,  0.6027, -0.3157],\n",
       "          [-0.6203, -1.2110, -0.1113],\n",
       "          [ 0.4412,  0.4374,  1.0628]],\n",
       "\n",
       "         [[ 0.0552,  0.3472,  0.0546],\n",
       "          [-0.0625,  0.0334,  0.7950],\n",
       "          [-1.0151,  0.0408, -1.5472]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2375, -0.4273, -0.0871],\n",
       "          [ 0.4409,  0.0725,  0.7220],\n",
       "          [-2.4041,  1.3587,  1.2033]],\n",
       "\n",
       "         [[-1.0719, -1.2230, -2.1777],\n",
       "          [ 0.0509,  0.2196,  0.1059],\n",
       "          [ 0.4083,  1.4222,  1.0656]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1861,  0.9263, -1.1957],\n",
       "          [ 0.0345,  0.1545,  1.0926],\n",
       "          [ 0.9858,  1.3075, -0.2445]],\n",
       "\n",
       "         [[-1.6937,  0.2222, -0.9520],\n",
       "          [ 1.5626, -1.4964,  2.3466],\n",
       "          [ 0.1503,  0.2342, -1.6386]]],\n",
       "\n",
       "\n",
       "        [[[ 0.8826, -0.4346, -0.2652],\n",
       "          [-0.0776,  1.2662, -0.3891],\n",
       "          [ 0.2385, -0.4247,  0.5400]],\n",
       "\n",
       "         [[ 2.3174, -0.0946,  1.1275],\n",
       "          [ 1.1084, -0.5001, -0.2187],\n",
       "          [ 1.2660,  0.7753, -1.9662]]]], requires_grad=True)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "norwegian-michigan",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-340-13b2d3b13c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "5 + None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-great",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
