{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "orange-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "path_train = '../data/train_data.pkl'\n",
    "path_val = '../data/val_data.pkl'\n",
    "\n",
    "noisy_imgs_1, noisy_imgs_2 = torch.load(path_train)\n",
    "noisy_imgs_1 = noisy_imgs_1[0:1].cpu().float()/256\n",
    "noisy_imgs_2 = noisy_imgs_2[0:1].cpu().float()/256\n",
    "\n",
    "noisy_imgs , clean_imgs = torch.load(path_val)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "protecting-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reliable-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import torch \n",
    "import torchvision \n",
    "import torchvision.transforms as T \n",
    "from PIL import Image\n",
    "\n",
    "transform = T.ToPILImage()\n",
    "# model = UNet(m=10).to(device)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(32,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 32)\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "\n",
    "batch_size, nb_epochs = 50, 2\n",
    "\n",
    "input = noisy_imgs_1.to(device).type(torch.float)\n",
    "target = noisy_imgs_2.to(device).type(torch.float)\n",
    "\n",
    "valid_inp = noisy_imgs.to(device).float()/256\n",
    "valid_target = clean_imgs.to(device).float()/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "institutional-flood",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pack_hook' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-687c1032d8ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_tensors_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpack_hook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pack_hook' is not defined"
     ]
    }
   ],
   "source": [
    "loss_tot = torch.zeros(nb_epochs)\n",
    "loss_valid = torch.zeros(nb_epochs)\n",
    "print(loss_tot)\n",
    "for e in tqdm(range(nb_epochs)):\n",
    "    model.train()\n",
    "    for i in range(len(input)):\n",
    "        with torch.autograd.graph.saved_tensors_hooks(pack_hook, unpack_hook):\n",
    "            output = model(input[i])\n",
    "            loss = mse(output, target[i])\n",
    "            loss_tot[e] += loss.item()    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    valid_output = model(valid_inp)\n",
    "    loss_valid[e] = mse(valid_output, valid_target).item()\n",
    "\n",
    "    if torch.remainder(torch.tensor(e), 100)==0:\n",
    "        plt.figure()\n",
    "        im = 0\n",
    "        im2 = 0\n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.imshow(transform(input[i][im]))\n",
    "        plt.colorbar()\n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.imshow(transform(output[im]))\n",
    "        plt.colorbar()\n",
    "        plt.subplot(2, 3, 3)\n",
    "        plt.imshow(transform(target[i][im]))\n",
    "        plt.colorbar()\n",
    "        plt.subplot(2, 3, 4)\n",
    "        plt.imshow(transform(valid_inp[im2]))\n",
    "        plt.colorbar()\n",
    "        plt.subplot(2, 3, 5)\n",
    "        plt.imshow(transform(valid_output[im2]))\n",
    "        plt.colorbar()\n",
    "        plt.subplot(2, 3, 6)\n",
    "        plt.imshow(transform(valid_target[im2]))\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "parallel-finance",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-dff0fda183bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "loss.grad_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-crack",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "equal-glory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packing None\n",
      "Packing <MulBackward0 object at 0x7ff4055cbcd0>\n",
      "Unpacking None\n",
      "Unpacking <MulBackward0 object at 0x7ff4055cb670>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def pack_hook(x):\n",
    "    print(\"Packing\", x.grad_fn)\n",
    "    return x\n",
    "\n",
    "def unpack_hook(x):\n",
    "    print(\"Unpacking\", x.grad_fn)\n",
    "    return x\n",
    "\n",
    "a = torch.ones(5, requires_grad=True) \n",
    "b = torch.ones(5, requires_grad=True) * 2\n",
    "with torch.autograd.graph.saved_tensors_hooks(pack_hook, unpack_hook):\n",
    "    y = a * b\n",
    "\n",
    "y.sum().backward()\n",
    "for param in model.parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adolescent-radiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1395,  0.1044,  0.0699,  ..., -0.0688,  0.1290, -0.0136],\n",
      "        [ 0.1739,  0.0215,  0.1039,  ..., -0.0597, -0.1578, -0.0652],\n",
      "        [ 0.1395,  0.1026, -0.0664,  ..., -0.1323, -0.0120,  0.1674],\n",
      "        ...,\n",
      "        [ 0.1614, -0.1582,  0.1572,  ...,  0.1293, -0.0373, -0.1709],\n",
      "        [-0.1542, -0.1628,  0.0750,  ..., -0.0703, -0.0104,  0.1745],\n",
      "        [ 0.1358, -0.1097,  0.1646,  ..., -0.1431,  0.0641,  0.1767]],\n",
      "       requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([-0.0865, -0.1354,  0.1431, -0.0722, -0.0232, -0.0983,  0.0983, -0.0306,\n",
      "        -0.0906,  0.1284, -0.0844, -0.0858,  0.1458,  0.1527,  0.0432,  0.0154,\n",
      "        -0.1741,  0.1381, -0.0223,  0.0559,  0.1607,  0.0329, -0.0994, -0.0819,\n",
      "         0.1051,  0.0989,  0.0545,  0.0862, -0.0085, -0.0838, -0.0527,  0.0626,\n",
      "         0.0955,  0.0160,  0.1733,  0.1276, -0.0569,  0.1512, -0.1199, -0.1473,\n",
      "         0.0900,  0.0088, -0.0015, -0.0227, -0.0821,  0.0275, -0.0999,  0.1200,\n",
      "        -0.0549,  0.1584, -0.0952,  0.1385, -0.1710, -0.0153,  0.0220, -0.1083,\n",
      "        -0.1449,  0.0921,  0.1682,  0.0576,  0.0768,  0.1214,  0.1451, -0.0754,\n",
      "         0.0998,  0.0286, -0.1359,  0.1144, -0.0178, -0.0755,  0.1510, -0.1379,\n",
      "        -0.0906,  0.1241, -0.0823, -0.0507, -0.1623,  0.1507,  0.1129, -0.1295,\n",
      "        -0.1329,  0.0208,  0.0690, -0.1305,  0.1363,  0.1388, -0.1462, -0.0994,\n",
      "        -0.0762, -0.1273, -0.0654, -0.0322, -0.0217, -0.1211, -0.0683,  0.0925,\n",
      "         0.0650,  0.1398,  0.0956, -0.1645], requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([[-0.0594,  0.0693,  0.0134,  ...,  0.0171,  0.0319, -0.0846],\n",
      "        [-0.0785,  0.0727,  0.0636,  ...,  0.0749, -0.0117,  0.0179],\n",
      "        [-0.0603,  0.0770, -0.0430,  ...,  0.0446,  0.0759, -0.0398],\n",
      "        ...,\n",
      "        [-0.0519, -0.0436, -0.0323,  ..., -0.0717,  0.0475,  0.0102],\n",
      "        [ 0.0917, -0.0579,  0.0063,  ...,  0.0388, -0.0185,  0.0702],\n",
      "        [-0.0668,  0.0284,  0.0777,  ..., -0.0223,  0.0502, -0.0324]],\n",
      "       requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([-0.0757, -0.0189, -0.0786,  0.0804, -0.0071,  0.0127, -0.0715, -0.0782,\n",
      "        -0.0650,  0.0917, -0.0396,  0.0332,  0.0057, -0.0227, -0.0866,  0.0380,\n",
      "        -0.0491, -0.0319,  0.0084, -0.0711,  0.0723,  0.0156,  0.0913,  0.0800,\n",
      "         0.0842, -0.0246,  0.0716,  0.0018,  0.0722,  0.0307,  0.0746,  0.0764],\n",
      "       requires_grad=True)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-apparel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "royal-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import unfold\n",
    "class relu(object) :\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, input) :\n",
    "        self.input = input\n",
    "        self.positif_mask = (input > 0)\n",
    "        return self.positif_mask*(input)\n",
    "    def backward(self, gradwrtoutput) :\n",
    "        self.input.grad = self.positif_mask.int()*gradwrtoutput\n",
    "        print('Our backward: ', self.input.grad)\n",
    "    def param(self) :\n",
    "        return []\n",
    "\n",
    "class sigmoid(object) :\n",
    "    def forward(self, input) :\n",
    "        self.input = input\n",
    "        self.output = 1/(1 + math.e**(-input))\n",
    "        return  self.output\n",
    "    def backward(self, gradwrtoutput ) :\n",
    "        self.input.grad = self.output * (1-self.output) * gradwrtoutput\n",
    "    def param(self) :\n",
    "        return []\n",
    "\n",
    "class convolution(object):\n",
    "    def __init__(self, inp_channels, out_channels, kernel_size = (3,3), stride = (1,1), padding = (0,0), dilation = (1,1)):\n",
    "        self.inp_channels = inp_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel = torch.empty((out_channels, kernel_size[0], kernel_size[1])).normal_()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        \n",
    "    def forward(self, input):\n",
    "        self.batch_size = input.size(0)\n",
    "        self.input = input\n",
    "        up = (input.size(-2) + 2 * self.padding[0] - self.dilation[0] * (self.kernel_size[0] - 1) - 1)\n",
    "        down = self.stride[0]\n",
    "        h = torch.tensor(up/down + 1).floor().int()\n",
    "        up = (input.size(-1) + 2 * self.padding[1] - self.dilation[1] * (self.kernel_size[1] - 1) - 1)\n",
    "        down = self.stride[1]\n",
    "        w = torch.tensor(up/down + 1).floor().int()\n",
    "        unf = unfold(input, kernel_size=self.kernel_size)\n",
    "        conv = self.kernel.view(self.out_channels, -1) @ unf\n",
    "#         print(conv.view(1, 1, 2, 2))\n",
    "#         print(h, w)\n",
    "        return conv.view(self.batch_size, self.out_channels, h, w)\n",
    "\n",
    "    def backward(self, gradwrtoutput):\n",
    "        flattened = gradwrtoutput.view(self.batch_size,self.out_channels,-1)\n",
    "        print(flattened)\n",
    "        pass\n",
    "    def param(self) :\n",
    "        return [self.kernel]\n",
    "    \n",
    "class mse(object):\n",
    "    def forward(self, input, target):\n",
    "        self.input = input\n",
    "        self.target = target\n",
    "        return (input - target).pow(2).mean(dim=[1, 2, 3]).sum()\n",
    "    def backward(self, gradwrtoutput):\n",
    "        self.input.grad = 2*(self.input-self.target)/(self.input.size(-3)*self.input.size(-2)*self.input.size(-1))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "valued-korea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0440,  0.9203,  0.1944],\n",
      "          [-0.5946, -0.4954, -1.9285],\n",
      "          [-1.0043, -1.0796, -0.2933]]]])\n",
      "tensor([[[[ 1.0904,  0.8289, -1.1416],\n",
      "          [ 1.1780,  0.8426, -1.1685],\n",
      "          [ 0.5877, -0.2360,  0.0489]]]], requires_grad=True)\n",
      "tensor([[[[0.7485, 0.6961, 0.2420],\n",
      "          [0.7646, 0.6990, 0.2371],\n",
      "          [0.6428, 0.4413, 0.5122]]]], grad_fn=<MulBackward0>)\n",
      "tensor([[[[0.7485, 0.6961, 0.2420],\n",
      "          [0.7646, 0.6990, 0.2371],\n",
      "          [0.6428, 0.4413, 0.5122]]]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(1.5910, grad_fn=<SumBackward0>)\n",
      "tensor(1.5910, grad_fn=<MseLossBackward0>)\n",
      "tensor([[[[ 0.0332, -0.0105,  0.0019],\n",
      "          [ 0.0544,  0.0558,  0.0871],\n",
      "          [ 0.0840,  0.0833,  0.0447]]]], grad_fn=<MulBackward0>)\n",
      "tensor([[[[ 0.0332, -0.0105,  0.0019],\n",
      "          [ 0.0544,  0.0558,  0.0871],\n",
      "          [ 0.0840,  0.0833,  0.0447]]]])\n"
     ]
    }
   ],
   "source": [
    "MSE = nn.MSELoss()\n",
    "\n",
    "target = torch.randn(1, 1, 3, 3)\n",
    "print(target)\n",
    "\n",
    "input = torch.randn(1, 1, 3, 3, requires_grad=True)\n",
    "input2 = input.detach().requires_grad_(True)\n",
    "\n",
    "print(input)\n",
    "# print(input2)\n",
    "model = sigmoid()\n",
    "model2 = torch.nn.Sigmoid()\n",
    "\n",
    "out = model.forward(input)\n",
    "out2 = model2.forward(input2)\n",
    "\n",
    "print(out)\n",
    "print(out2)\n",
    "my_mse = mse()\n",
    "loss = my_mse.forward(out, target)\n",
    "loss2 = MSE(out2, target)\n",
    "\n",
    "print(loss)\n",
    "print(loss2)\n",
    "my_mse.backward(loss)\n",
    "model.backward(my_mse.input.grad)\n",
    "\n",
    "loss2.backward()\n",
    "\n",
    "# print(model.input.grad)\n",
    "\n",
    "print(input.grad)\n",
    "print(input2.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24f9ffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.4373e+01,  8.9594e+00,  8.2914e+00, -3.2300e+01, -8.2132e+00,\n",
      "          -3.5403e+00, -3.8366e+01,  4.4688e+01, -4.9594e+01,  6.8135e+00,\n",
      "          -2.9135e+01, -6.3563e+00,  1.9680e+01,  1.0055e+01, -4.6699e+00,\n",
      "           1.2237e+01,  7.4446e-01, -2.1380e+01,  2.1600e+00,  8.1567e+00,\n",
      "          -9.0960e+00,  4.4997e+01, -2.2331e+01,  4.7453e+01,  1.4016e+00],\n",
      "         [-2.1148e+01, -4.0760e+01,  1.7178e+01,  5.6863e+01, -6.8904e+00,\n",
      "          -6.7906e-02, -3.9611e+01,  2.9627e+00,  4.0970e+01, -1.6927e+01,\n",
      "           3.9700e+01, -1.3491e+01,  2.9640e+00, -7.9330e+01,  3.3416e+01,\n",
      "          -5.3917e+00,  2.1418e+01,  4.4497e+01, -7.2982e+01,  4.7925e+01,\n",
      "          -5.2293e+01,  6.1290e+00,  1.6297e+01,  3.4601e+00,  1.1976e+01],\n",
      "         [ 3.2122e+00,  4.1303e+00,  1.8777e+01,  8.4691e+00, -8.9788e+00,\n",
      "           1.0548e+01, -3.5732e+00,  2.5001e+01, -3.3122e+01, -6.3945e+00,\n",
      "           4.9866e+00, -6.2900e+00,  9.1395e+00, -4.7929e+01, -2.1028e+01,\n",
      "          -3.8644e+01, -2.9606e+01,  2.3409e+00,  3.0415e+01,  1.1559e+01,\n",
      "           1.0626e+01,  5.8642e+01,  3.2722e+01,  4.8222e+01, -4.3880e+00]]])\n"
     ]
    }
   ],
   "source": [
    "test_conv = convolution(1, 3, kernel_size = (3,3))\n",
    "dummy_input = (torch.empty((1,1,7,7)).normal_()*10)\n",
    "test_conv.backward(test_conv.forward(dummy_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9db99be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tensor([-1.1305,  1.1211,  2.8137,  3.1344,  0.6033])\n",
      "output:  tensor([-0.0000, 1.1211, 2.8137, 3.1344, 0.6033], grad_fn=<MulBackward0>)\n",
      "output_comp:  tensor([0.0000, 1.1211, 2.8137, 3.1344, 0.6033], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mse() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-287704a8f5e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmse_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mloss_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_comp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_comp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mse() takes no arguments"
     ]
    }
   ],
   "source": [
    "inp = torch.normal(torch.zeros(5), torch.ones(5)*2)\n",
    "print('input: ', inp)\n",
    "tar = torch.round(inp).requires_grad_(True)\n",
    "model= relu()\n",
    "model_comp = torch.nn.ReLU()\n",
    "inp\n",
    "inp.requires_grad_(True)\n",
    "inp_comp = inp.clone()\n",
    "out = model.forward(inp)\n",
    "out_comp = model_comp(inp)\n",
    "print('output: ', out)\n",
    "print('output_comp: ', out_comp)\n",
    "\n",
    "mse_comp = torch.nn.MSELoss()\n",
    "loss = mse(out,tar)\n",
    "loss_comp = mse_comp(out_comp,tar)\n",
    "print('loss: ', loss)\n",
    "print('loss_comp: ', loss_comp)\n",
    "\n",
    "\n",
    "print(model.backward(loss))\n",
    "loss_comp.backward()\n",
    "print(inp_comp.grad)\n",
    "print(out_comp.grad)\n",
    "# torch.autograd.grad(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-update",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(inp,out, '.')\n",
    "plt.plot(inp,tar, '.')\n",
    "plt.plot(inp, loss, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-wallace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "imperial-candy",
   "metadata": {},
   "source": [
    "(a > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a > 0).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-adjustment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
