{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dutch-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import empty , cat , arange\n",
    "from torch.nn.functional import fold , unfold\n",
    "\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    kernel_size = (2 , 2)\n",
    "    x = torch.randn((1 , 3 , 32 , 32) )\n",
    "    y = torch.randn((1 , 3 , 32 , 32) )\n",
    "    a = torch.randn((1 ,) )\n",
    "\n",
    "    out_channels = 4\n",
    "\n",
    "    conv = torch.nn.Conv2d( in_channels = x.shape[1], out_channels = out_channels, kernel_size = kernel_size, bias = False )\n",
    "\n",
    "    torch.testing.assert_allclose(a*conv(x) , conv(a*x))\n",
    "    torch.testing.assert_allclose(conv(x + y) , conv(x) + conv(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "selected-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def forward(x):\n",
    "        return max(0,x)\n",
    "    def backward(x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "raised-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22.911159535680525 [[0.        ]\n",
      " [4.47982444]\n",
      " [1.37250687]\n",
      " [3.26545862]]\n",
      "22.911159535680525 [[0.        ]\n",
      " [6.95964889]\n",
      " [0.74501375]\n",
      " [6.53091724]]\n",
      "22.911159535680525 [[ 0.15368991]\n",
      " [20.26117228]\n",
      " [ 0.98598533]\n",
      " [ 8.39311763]\n",
      " [ 0.        ]\n",
      " [ 2.36118507]\n",
      " [ 0.        ]\n",
      " [ 9.72710384]\n",
      " [ 1.25375695]\n",
      " [26.2976303 ]\n",
      " [ 0.09610849]\n",
      " [ 6.0524677 ]\n",
      " [ 9.60683664]\n",
      " [ 0.        ]\n",
      " [ 4.3578115 ]\n",
      " [16.65728166]\n",
      " [ 0.22008463]\n",
      " [30.48500084]\n",
      " [ 1.51224854]\n",
      " [ 1.29991433]\n",
      " [ 0.        ]\n",
      " [ 0.08865605]\n",
      " [ 0.        ]\n",
      " [ 7.20681283]\n",
      " [15.59825335]\n",
      " [ 0.03303839]\n",
      " [11.26781143]\n",
      " [ 2.1551471 ]\n",
      " [ 0.15365547]\n",
      " [ 0.        ]]\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         2.06408472 0.14167171 1.20596854 0.         0.\n",
      "  0.         0.53295282 0.         1.34932931 0.         0.\n",
      "  0.         0.         0.51487742 1.60468168 0.         1.40619507\n",
      "  0.21728805 0.18677872 0.         0.         0.         0.92098397\n",
      "  0.67963815 0.         1.27943089 0.15360443 0.         0.        ]\n",
      " [0.20629137 0.         0.         0.         0.         0.33676034\n",
      "  0.         0.34872081 0.75196423 1.11249186 0.1290023  1.08584047\n",
      "  1.53334785 0.         0.         0.         0.29541016 1.58256494\n",
      "  0.         0.         0.         0.11899922 0.         0.\n",
      "  0.88367384 0.00512606 0.         0.01139873 0.20624514 0.        ]\n",
      " [0.         0.90276253 0.         0.         0.         0.32312368\n",
      "  0.         0.88167363 0.10619232 2.46182117 0.         0.80287369\n",
      "  1.29606166 0.         0.11858142 0.84050377 0.         2.98876001\n",
      "  0.         0.         0.         0.         0.         0.12204836\n",
      "  1.56331199 0.00447401 0.36188204 0.16500316 0.         0.        ]]\n",
      "22.911159535680525 [[  0.           0.           0.          -0.           0.\n",
      "    0.           0.          -0.          -0.          -0.\n",
      "   -0.           0.          -0.          -0.           0.\n",
      "   -0.          -0.           0.           0.           0.\n",
      "   -0.           0.          -0.           0.           0.\n",
      "   -0.           0.          -0.          -0.          -0.        ]\n",
      " [  0.82631228   4.89973312  13.29883896  -0.4206145    7.29178341\n",
      "   16.57931079   3.23150966  -2.19435628  -2.54375107  -3.2373377\n",
      "   -9.93834264   2.7944864   -4.05971255  -4.69350333  10.30736311\n",
      "   -3.66956902  -1.93689556   7.83051132   2.17752171   6.53718614\n",
      "   -9.28906853  13.47205427  -6.6578428    9.40665267   2.58837212\n",
      "   -7.54735327   3.39897457 -10.87055031  -4.83556607  -0.38036895]\n",
      " [  0.08845475   0.5245047    1.42360887  -0.04502578   0.78056795\n",
      "    1.77477552   0.34592537  -0.23490059  -0.27230246  -0.34654925\n",
      "   -1.06387578   0.29914308  -0.43458251  -0.50242829   1.10337854\n",
      "   -0.39281858  -0.20734003   0.83823749   0.23309848   0.69979012\n",
      "   -0.99437254   1.44215115  -0.71270613   1.00695964   0.27707904\n",
      "   -0.8079261    0.36385209  -1.16366638  -0.51763577  -0.04071758]\n",
      " [  0.7754094    4.59789739  12.47959746  -0.3947036    6.84259145\n",
      "   15.55798409   3.03244064  -2.05917848  -2.38704968  -3.03790966\n",
      "   -9.32611606   2.6223391   -3.80962418  -4.40437188   9.67240395\n",
      "   -3.44351445  -1.81757799   7.34813239   2.04338096   6.13447924\n",
      "   -8.71683885  12.64214228  -6.24770315   8.82717951   2.42892197\n",
      "   -7.08241757   3.1895893  -10.20089743  -4.5376832   -0.35693728]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# N is batch size(sample size); D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 4, 2, 30, 1\n",
    "\n",
    "# Create random input and output data\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 0.002\n",
    "loss_col = []\n",
    "for t in range(1):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)  # using ReLU as activate function\n",
    "    y_pred = h_relu.dot(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum() # loss function\n",
    "    loss_col.append(loss)\n",
    "    print(t, loss, y_pred)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y) # the last layer's error\n",
    "    print(loss, grad_y_pred)\n",
    "    \n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    print(loss, grad_w2)\n",
    "    print(h_relu)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T) # the second laye's error \n",
    "    print(loss, grad_h_relu)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0  # the derivate of ReLU\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # Update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "\n",
    "plt.plot(loss_col)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "previous-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(32,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 32)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-patio",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-musical",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
