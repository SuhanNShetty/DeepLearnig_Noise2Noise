{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba34b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4397,  0.2831,  1.5650, -0.5245, -2.0008,  2.2580, -0.0792, -0.3956,\n",
      "         -0.0845,  0.1205,  1.9671,  1.1400,  0.6991,  1.2292,  0.2043, -0.0662,\n",
      "         -0.2540, -1.3839,  0.3893,  0.4615,  0.6654,  0.5382,  0.5478,  1.1590,\n",
      "         -0.8607]])\n",
      "tensor([[-0.4397,  0.2831,  1.5650, -0.5245, -2.0008],\n",
      "        [ 2.2580, -0.0792, -0.3956, -0.0845,  0.1205],\n",
      "        [ 1.9671,  1.1400,  0.6991,  1.2292,  0.2043],\n",
      "        [-0.0662, -0.2540, -1.3839,  0.3893,  0.4615],\n",
      "        [ 0.6654,  0.5382,  0.5478,  1.1590, -0.8607]])\n",
      "tensor([[-0.8607,  1.1590,  0.5478,  0.5382,  0.6654],\n",
      "        [ 0.4615,  0.3893, -1.3839, -0.2540, -0.0662],\n",
      "        [ 0.2043,  1.2292,  0.6991,  1.1400,  1.9671],\n",
      "        [ 0.1205, -0.0845, -0.3956, -0.0792,  2.2580],\n",
      "        [-2.0008, -0.5245,  1.5650,  0.2831, -0.4397]])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "from torch import empty , cat , arange\n",
    "from torch.nn.functional import fold , unfold\n",
    "\n",
    "kernel = empty((5,5)).normal_()\n",
    "print(kernel.view(1,-1))\n",
    "print(kernel)\n",
    "print(kernel.flip((0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e85a7345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2661, -0.5691, -0.1831],\n",
      "        [-0.8653, -0.5603, -0.5318],\n",
      "        [-0.2112,  0.7639, -0.5779]])\n",
      "tensor([[-0.5779,  0.7639, -0.2112],\n",
      "        [-0.5318, -0.5603, -0.8653],\n",
      "        [-0.1831, -0.5691,  0.2661]])\n"
     ]
    }
   ],
   "source": [
    "kernel = empty((3,3)).normal_()\n",
    "print(kernel)\n",
    "print(kernel.flip(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "24efb6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class relu(object) :\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, input) :\n",
    "        self.input = input\n",
    "        self.positif_mask = (input > 0)\n",
    "        return self.positif_mask*(input)\n",
    "    def backward(self, gradwrtoutput) :\n",
    "        self.input.grad = self.positif_mask.int()*gradwrtoutput\n",
    "        return self.input.grad\n",
    "    def param(self) :\n",
    "        return []\n",
    "\n",
    "class sigmoid(object) :\n",
    "    def forward(self, input) :\n",
    "        self.input = input\n",
    "        self.output = 1/(1 + math.e**(-input))\n",
    "        return  self.output\n",
    "    def backward(self, gradwrtoutput ) :\n",
    "        self.input.grad = self.output * (1-self.output) * gradwrtoutput\n",
    "        return self.input.grad\n",
    "    def param(self) :\n",
    "        return []\n",
    "\n",
    "class convolution(object):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size = (3,3), padding = 0, stride = 1, use_bias = False):\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.kernel_size = kernel_size\n",
    "        self.k_1 = self.kernel_size[0]\n",
    "        self.k_2 = self.kernel_size[1]\n",
    "        self.use_bias = use_bias\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.kernel = empty(out_ch, in_ch, self.k_1, self.k_2).normal_()\n",
    "        self.bias = empty(out_ch).normal_() if use_bias else 0 *empty(out_ch)\n",
    "        \n",
    "    def forward(self, x):   \n",
    "        self.x = x\n",
    "        self.batch_size = x.size(0)\n",
    "        X_unf = unfold(x, kernel_size=(self.k_1, self.k_2), padding = self.padding, stride = self.stride)\n",
    "        K_expand = self.kernel.view(self.out_ch, -1)\n",
    "        O_expand = K_expand @ X_unf\n",
    "        s1 = math.ceil((x.size(-2)-self.k_1+1+self.padding*2)/(self.stride))\n",
    "        s2 = math.ceil((x.size(-1)-self.k_2+1+self.padding*2)/(self.stride))\n",
    "\n",
    "        O = O_expand.view(self.batch_size, self.out_ch, s1, s2)\n",
    "        return O + self.bias.view(1, -1, 1, 1) if self.use_bias else O\n",
    "    \n",
    "    def backward(self, gradwrtoutput):\n",
    "        kernel_back = self.kernel.flip(-2, -1).transpose(0,1)\n",
    "        s1 = self.x.size(-2)\n",
    "        s2 = self.x.size(-1)\n",
    "        \n",
    "        # backward wrt input\n",
    "        M = self.get_M(s1-self.k_1 + 1 + self.padding*2)\n",
    "        dL_dO = (M.transpose(0,1) @ gradwrtoutput) @ M\n",
    "\n",
    "        dL_dO_unf = unfold(dL_dO, kernel_size=(k_1, k_2), padding = (k_1 - 1 - self.padding, k_2-1- self.padding), stride = 1)\n",
    "        dO_dX_exp = kernel_back.reshape(self.in_ch, -1)\n",
    "        dL_dX_exp = dO_dX_exp @ dL_dO_unf\n",
    "        dL_dX = dL_dX_exp.view(self.batch_size, self.in_ch, s1, s2)\n",
    "        \n",
    "        self.dL_dO = dL_dO.transpose(0,1) # K\n",
    "        self.dO_dF = self.x.view(self.in_ch, self.batch_size, s1, s2).transpose(0,1) # X\n",
    "        \n",
    "        # backward wrt weights\n",
    "        dL_dO_unf_F = self.dL_dO.reshape(self.out_ch, -1)\n",
    "        dO_dF_exp = unfold(self.dO_dF, kernel_size = (s1 - self.k_1 +1 + self.padding*2, s2 - self.k_2 +1 + self.padding*2), padding = self.padding, stride = 1)\n",
    "        dL_dF_exp = dL_dO_unf_F @ dO_dF_exp\n",
    "        dL_dF = dL_dF_exp.transpose(0,1).view(self.kernel.size())\n",
    "        \n",
    "        # backward wrt bias\n",
    "        if self.use_bias:\n",
    "            dL_dO_exp = self.dL_dO.reshape(self.out_ch, -1)\n",
    "            dO_dB_exp = torch.ones(self.batch_size * (s1 - self.k_1 +1 + self.padding*2) * (s2 - self.k_2 +1 + self.padding*2))\n",
    "            dL_dB = dL_dO_exp @ dO_dB_exp\n",
    "        else:\n",
    "            dL_dB = None\n",
    "        return dL_dX, dL_dF, dL_dB\n",
    "    \n",
    "    def get_M(self, N):\n",
    "        diag = empty(N)\n",
    "        eye_N = (diag == diag).float().diag()\n",
    "        return eye_N[range(0,N,self.stride)]\n",
    "        \n",
    "    def param(self) :\n",
    "        return [self.kernel, self.bias]\n",
    "    \n",
    "class mse(object):\n",
    "    def forward(self, input, target):\n",
    "        self.input = input\n",
    "        self.target = target\n",
    "        return (input - target).pow(2).mean()\n",
    "    def backward(self, gradwrtoutput):\n",
    "        self.input.grad = 2*(self.input-self.target)/(self.input.size(-3)*self.input.size(-2)*self.input.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "db59eb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6332, 1.3556, 0.9980, 1.1980, 0.0522],\n",
      "          [-0.0000, 0.8747, -0.0000, 1.3845, -0.0000],\n",
      "          [0.7899, -0.0000, 0.0772, 0.7219, -0.0000],\n",
      "          [0.2408, 0.6669, -0.0000, -0.0000, -0.0000],\n",
      "          [2.5453, -0.0000, 1.1522, 0.0190, 1.1587]]]])\n",
      "tensor([[[[0.6332, 1.3556, 0.9980, 1.1980, 0.0522],\n",
      "          [-0.0000, 0.8747, -0.0000, 1.3845, -0.0000],\n",
      "          [0.7899, -0.0000, 0.0772, 0.7219, -0.0000],\n",
      "          [0.2408, 0.6669, -0.0000, -0.0000, -0.0000],\n",
      "          [2.5453, -0.0000, 1.1522, 0.0190, 1.1587]]]])\n"
     ]
    }
   ],
   "source": [
    "input = empty((1,1,5,5)).normal_()\n",
    "test = relu()\n",
    "print(test.forward(input))\n",
    "print(test.backward(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "10881dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5825, 0.4077, 0.9503, 0.4043, 0.5982],\n",
      "          [0.5541, 0.2446, 0.5082, 0.6013, 0.5563],\n",
      "          [0.5330, 0.8787, 0.3567, 0.6566, 0.7053],\n",
      "          [0.6171, 0.7591, 0.4651, 0.6924, 0.7866],\n",
      "          [0.8103, 0.4861, 0.5083, 0.4181, 0.6746]]]])\n",
      "tensor([[[[ 0.0810, -0.0902,  0.1393, -0.0933,  0.0956],\n",
      "          [ 0.0537, -0.2084,  0.0082,  0.0985,  0.0558],\n",
      "          [ 0.0329,  0.2111, -0.1353,  0.1461,  0.1814],\n",
      "          [ 0.1127,  0.2099, -0.0348,  0.1728,  0.2190],\n",
      "          [ 0.2232, -0.0138,  0.0083, -0.0804,  0.1601]]]])\n"
     ]
    }
   ],
   "source": [
    "test = sigmoid()\n",
    "print(test.forward(input))\n",
    "print(test.backward(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4cb97f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 6.1688,  0.8555,  2.7351],\n",
      "          [ 7.6526,  0.7513, -0.9575],\n",
      "          [ 5.2676,  3.7301, -1.1703]],\n",
      "\n",
      "         [[ 0.8378, -2.5154,  1.2878],\n",
      "          [ 4.1992, -3.3236,  0.8735],\n",
      "          [ 0.7682,  0.3650,  1.6813]],\n",
      "\n",
      "         [[ 0.1420,  7.7649,  9.1296],\n",
      "          [ 1.4210,  3.6245,  3.5923],\n",
      "          [ 7.8587,  4.5758,  1.2232]]]])\n",
      "tensor([[1, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [0, 0, 1]], dtype=torch.int32)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5x5 and 3x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [84]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m test \u001b[38;5;241m=\u001b[39m convolution(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(test\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28minput\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[1;32mIn [81]\u001b[0m, in \u001b[0;36mconvolution.backward\u001b[1;34m(self, gradwrtoutput)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# backward wrt input\u001b[39;00m\n\u001b[0;32m     56\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_M(s1\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m dL_dO \u001b[38;5;241m=\u001b[39m (\u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgradwrtoutput\u001b[49m) \u001b[38;5;241m@\u001b[39m M\n\u001b[0;32m     59\u001b[0m dL_dO_unf \u001b[38;5;241m=\u001b[39m unfold(dL_dO, kernel_size\u001b[38;5;241m=\u001b[39m(k_1, k_2), padding \u001b[38;5;241m=\u001b[39m (k_1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, k_2\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding), stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     60\u001b[0m dO_dX_exp \u001b[38;5;241m=\u001b[39m kernel_back\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_ch, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (5x5 and 3x3)"
     ]
    }
   ],
   "source": [
    "test = convolution(1,3)\n",
    "print(test.forward(input))\n",
    "print(test.backward(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "25af2a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = empty(5).normal_().diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a05dd682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0959,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  1.1059,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -1.5449,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, -0.5452,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.4348]])\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e38f0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
